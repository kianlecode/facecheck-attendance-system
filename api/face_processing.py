from ultralytics import YOLO
import numpy as np
import cv2
from deepface import DeepFace
import base64
import mediapipe as mp

# === Load YOLOv8 model ===
yolo_model = YOLO("models/yolov8n-face.pt")  # ho·∫∑c model kh√°c n·∫øu b·∫°n c√≥
MODEL_NAME = "ArcFace"

# === Load MediaPipe FaceMesh model ===
mp_face_mesh = mp.solutions.face_mesh
face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True, refine_landmarks=True)

def decode_base64_to_image(base64_str):
    img_data = base64.b64decode(base64_str.split(",")[1])
    np_arr = np.frombuffer(img_data, np.uint8)
    img = cv2.imdecode(np_arr, cv2.IMREAD_COLOR)
    return img

def detect_face_yolo(image):
    results = yolo_model.predict(image, imgsz=640, conf=0.4)
    boxes = results[0].boxes.xyxy.cpu().numpy() if results and results[0].boxes else []
    return boxes

def crop_face(image, box):
    x1, y1, x2, y2 = map(int, box)
    x1 = max(0, x1)
    y1 = max(0, y1)
    x2 = min(image.shape[1], x2)
    y2 = min(image.shape[0], y2)
    return image[y1:y2, x1:x2]

def extract_embedding(face_image):
    try:
        print("üì¶ B·∫Øt ƒë·∫ßu tr√≠ch xu·∫•t vector t·ª´ ·∫£nh m·∫∑t...")
        rgb = cv2.cvtColor(face_image, cv2.COLOR_BGR2RGB)
        temp_path = "temp_face.jpg"
        cv2.imwrite(temp_path, rgb)
        print(f"‚úÖ ·∫¢nh t·∫°m ƒë√£ l∆∞u t·∫°i: {temp_path}")

        from deepface import DeepFace
        embedding = DeepFace.represent(
            img_path=temp_path,
            model_name="ArcFace",
            enforce_detection=False
        )
        print("üß† B·∫Øt ƒë·∫ßu DeepFace.represent...")
        print("üéØ K·∫øt qu·∫£ embedding:", embedding)

        if not embedding or 'embedding' not in embedding[0]:
            print("‚ùå Kh√¥ng t√¨m th·∫•y tr∆∞·ªùng 'embedding'")
            return None

        return np.array(embedding[0]['embedding'], dtype=np.float32)

    except Exception as e:
        print("üõë L·ªói khi tr√≠ch xu·∫•t embedding:", e)
        return None

def process_face_from_base64(base64_str):
    img = decode_base64_to_image(base64_str)
    boxes = detect_face_yolo(img)

    if len(boxes) == 0:
        print("‚ùå Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t.")
        return None

    if len(boxes) > 1:
        print("üö® Ph√°t hi·ªán nhi·ªÅu h∆°n 1 khu√¥n m·∫∑t! H·ªá th·ªëng t·ª´ ch·ªëi x·ª≠ l√Ω.")
        return None

    face_img = crop_face(img, boxes[0])

    # ‚úÖ Resize khu√¥n m·∫∑t v·ªÅ 112x112 ƒë·ªÉ ƒë·ªìng b·ªô v·ªõi ArcFace
    face_resized = cv2.resize(face_img, (112, 112))

    return extract_embedding(face_resized)


def detect_face_box_from_base64(base64_str):
    img = decode_base64_to_image(base64_str)
    boxes = detect_face_yolo(img)
    if len(boxes) == 0:
        return None
    box = boxes[0]
    return {
        "x1": int(box[0]),
        "y1": int(box[1]),
        "x2": int(box[2]),
        "y2": int(box[3])
    }

def predict_pose(face_img):
    rgb_image = cv2.cvtColor(face_img, cv2.COLOR_BGR2RGB)
    results = face_mesh.process(rgb_image)

    if not results.multi_face_landmarks:
        print("[DEBUG] Kh√¥ng t√¨m th·∫•y landmarks")
        return "unknown"

    landmarks = results.multi_face_landmarks[0].landmark

    nose = landmarks[1]
    left_cheek = landmarks[234]
    right_cheek = landmarks[454]

    offset = nose.x - ((left_cheek.x + right_cheek.x) / 2)
    print("[DEBUG] Offset X:", offset)

    if abs(offset) < 0.02:
        return "front"
    elif offset < -0.04:
        return "left"
    elif offset > 0.04:
        return "right"
    else:
        return "unknown"

def predict_pose_from_base64(base64_str):
    try:
        img = decode_base64_to_image(base64_str)
        boxes = detect_face_yolo(img)
        # print("[DEBUG] YOLO boxes:", boxes)

        if boxes is None or len(boxes) == 0:
            # print("[DEBUG] Kh√¥ng t√¨m th·∫•y box YOLO")
            return {
                "success": False,
                "message": "Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t"
            }

        if len(boxes) > 1:
            # print("üö® Ph√°t hi·ªán nhi·ªÅu h∆°n 1 khu√¥n m·∫∑t!")
            return {
                "success": False,
                "message": "Ph√°t hi·ªán nhi·ªÅu khu√¥n m·∫∑t. Vui l√≤ng ch·ªâ ƒë·ªÉ 1 ng∆∞·ªùi trong camera."
            }

        box = boxes[0]
        face_img = crop_face(img, box)
        # print("[DEBUG] Box to·∫° ƒë·ªô:", box)
        # print("[DEBUG] Face shape:", face_img.shape)

        face_resized = cv2.resize(face_img, (320, 320))  # MediaPipe ho·∫°t ƒë·ªông t·ªët ·ªü k√≠ch th∆∞·ªõc n√†y
        pose = predict_pose(face_resized)

        return {
            "success": True,
            "pose": pose  # ‚úÖ Tr·∫£ chu·ªói tr·ª±c ti·∫øp thay v√¨ object l·ªìng
        }

    except Exception as e:
        # print("[ERR] predict_pose_from_base64 l·ªói:", e)
        return {
            "success": False,
            "message": "L·ªói x·ª≠ l√Ω pose: " + str(e)
        }